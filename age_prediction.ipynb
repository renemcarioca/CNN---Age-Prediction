{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reg-age-prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9XLm6nRZtENTcd/Nw1Wxw"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "pAhQV2FjQIkm"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "# !chmod 600 '/content/kaggle.json'\n",
        "# !kaggle datasets download -d mariafrenti/age-prediction\n",
        "# !unzip -q age-prediction.zip\n",
        "# !rm age-prediction.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1001\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "# Typings\n",
        "from typing import Tuple, Callable, List, Union, Dict, Iterable, Iterator, Optional\n",
        "from tensorflow.python.data.ops.dataset_ops import BatchDataset\n",
        "import functools\n",
        "\n",
        "# Padronizando a aleatoriedade\n",
        "rng = np.random.default_rng(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "python_random.seed(SEED)"
      ],
      "metadata": {
        "id": "s1D4ImkeQQNa"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_COLOR_CHANNELS = 3\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "INPUT_SHAPE = (*IMAGE_SIZE, NUM_OF_COLOR_CHANNELS)\n",
        "BATCH_INPUT_SHAPE = (None, *INPUT_SHAPE)\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com base nos arquivos dos diretórios.\n",
        "    - path: caminho base para as pastas\n",
        "'''\n",
        "def _load_data(path: str, subset: str = None, validation_split: float = None) -> tf.data.Dataset:\n",
        "    return keras.preprocessing.image_dataset_from_directory(\n",
        "        path,\n",
        "        seed=SEED,\n",
        "        validation_split=validation_split,\n",
        "        subset=subset,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "_20to50_dir = \"20-50/20-50\"\n",
        "_1to100_dir = \"age_prediction_up/age_prediction\"\n",
        "\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com as imagens e labels já apropriados para treinamento\n",
        "    - all_ages: se deve ser usado o diretório com idades de 1 a 100\n",
        "    - train: se deve ser usado o conjunto de treino\n",
        "    (será usado teste caso contrário)\n",
        "    - regression: se os labels devem ser transformados para tarefas de regressão\n",
        "    (será transformado para classificação caso contrário)\n",
        "'''\n",
        "def load_data(all_ages: bool, train: bool, regression: bool, subset: str = None, validation_split: float = None) -> tf.data.Dataset:\n",
        "    base_dir = _1to100_dir if all_ages else _20to50_dir\n",
        "    folder = \"train\" if train else \"test\"\n",
        "    age_count = 100 if all_ages else 31\n",
        "    data = _load_data(f\"{base_dir}/{folder}\", subset, validation_split)\n",
        "    if regression:\n",
        "        return data.map(lambda x, y: (x, y / (age_count - 1)))\n",
        "    return data.map(lambda x, y: (x, tf.one_hot(y, depth=age_count)))"
      ],
      "metadata": {
        "id": "w5FrxKPlQRx_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob2 import glob\n",
        "\n",
        "''' Retorna uma np.ndarray com todos os caminhos até as imagens '''\n",
        "def get_image_paths(all_ages: bool, train: bool) -> np.ndarray:\n",
        "    base_dir = _1to100_dir if all_ages else _20to50_dir\n",
        "    folder = \"train\" if train else \"test\"\n",
        "    return np.array(sorted(glob(f'{base_dir}/{folder}/*/*.jpg')))\n",
        "\n",
        "'''\n",
        "    Retorna a imagem e o label associado a um caminho.\n",
        "    O label já é transformado apropriadamente\n",
        "'''\n",
        "def load_image(path: str, regression: bool):\n",
        "    parts = path.split(os.sep)\n",
        "    age = int(parts[3])\n",
        "    all_ages = parts[0] != '20-50'\n",
        "    age_count = 100 if all_ages else 31\n",
        "    offset = 1 if all_ages else 20\n",
        "    if regression:\n",
        "        label = tf.convert_to_tensor((age - offset) / (age_count - 1))\n",
        "    else:\n",
        "        label = tf.one_hot(age - offset, depth=age_count)\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    return image, label\n",
        "\n",
        "'''\n",
        "    Retorna um gerador que pode ser usado para iterar por todas as imagens\n",
        "    nos caminhos especificados.\n",
        "    Construa um Dataset com tf.data.Dataset.from_generator\n",
        "'''\n",
        "def build_images_generator(paths: List[str], regression: bool):\n",
        "    def gen():\n",
        "        i = 0\n",
        "        num_of_files = len(paths)\n",
        "        while i < num_of_files:\n",
        "            yield load_image(paths[i], regression)\n",
        "            i += 1\n",
        "    return gen\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com todas as imagens e seus respectivos labels (já transformados)\n",
        "\n",
        "'''\n",
        "def build_ds_from_paths(paths: List[str], regression: bool, batch_size=BATCH_SIZE) -> tf.data.Dataset:\n",
        "    all_ages = paths[0].split(os.sep)[0] != '20-50'\n",
        "    age_count = 100 if all_ages else 31\n",
        "    label_shape = () if regression else (age_count,)\n",
        "    input_shape = INPUT_SHAPE\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        build_images_generator(paths, regression),\n",
        "        output_types=(tf.uint8, tf.float32), \n",
        "        output_shapes=(input_shape, label_shape),\n",
        "    ).batch(BATCH_SIZE)\n",
        "\n",
        "def build_ds_from_index(index: List[int], all_ages: bool, train: bool, regression: bool, batch_size=BATCH_SIZE) -> tf.data.Dataset:\n",
        "    paths = get_image_paths(all_ages, train)[index]\n",
        "    return build_ds_from_paths(paths, regression, batch_size)\n",
        "\n",
        "'''\n",
        "    Mapeia labels ou predições, que são valores em [0, 1], para idades.\n",
        "    Na classificação, há codificação one-hot\n",
        "\n",
        "    A idade retornada na classificação é aquela associada à classe\n",
        "    com maior propabilidade.\n",
        "'''\n",
        "def map_to_ages(labels, all_ages: bool, regression: bool):\n",
        "    scale = (99 if all_ages else 30) if regression else 1\n",
        "    offset = 1 if all_ages else 20\n",
        "    if not regression:\n",
        "        labels = np.argmax(labels, axis=-1)\n",
        "    return labels * scale + offset"
      ],
      "metadata": {
        "id": "TTRlbaT_QTl3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 5000\n",
        "validation_split = 0.2\n",
        "\n",
        "train_paths = get_image_paths(all_ages=False, train=True)\n",
        "train_paths_sample = np.random.choice(train_paths, SAMPLE_SIZE)\n",
        "\n",
        "tr_paths, valid_paths = train_test_split(train_paths_sample, test_size=0.2)\n",
        "\n",
        "sample_ds_train = build_ds_from_paths(tr_paths, regression=True)\n",
        "sample_ds_valid = build_ds_from_paths(valid_paths, regression=True)"
      ],
      "metadata": {
        "id": "fj7DuMfRn6Vk"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_only_normalization = keras.Sequential([\n",
        "    layers.Rescaling(1./255, batch_input_shape=BATCH_INPUT_SHAPE)\n",
        "], name='only_normalization')\n",
        "preprocess = keras.Sequential(\n",
        "    [\n",
        "        layers.Resizing(*IMAGE_SIZE, batch_input_shape=BATCH_INPUT_SHAPE),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomTranslation(0.1, 0.1),\n",
        "        layers.RandomZoom(0.1, 0.1),\n",
        "        layers.RandomContrast(0.1),\n",
        "        _only_normalization,\n",
        "    ], name='preprocess'\n",
        ")"
      ],
      "metadata": {
        "id": "uy_-4rBBQYOr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchify(image: np.ndarray) -> np.ndarray:\n",
        "    if len(image.shape) == len(INPUT_SHAPE):\n",
        "        # o modelo (incluindo pré-processamento) espera a entrada em mini-batches\n",
        "        # caso uma única imagem seja passada, modificamos seu formato\n",
        "        # para 1 batch de 1 imagem\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "    return image\n",
        "\n",
        "'''\n",
        "    Exibe uma image.\n",
        "'''\n",
        "def plot_single_image(image: np.ndarray, age: Optional[int] = None, apply=None):\n",
        "    if apply is not None:\n",
        "        image = apply(batchify(image))[0]\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "    if age is not None:\n",
        "        ax.set_title(age)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "def plot_samples(images, ages: Iterable[int], ncols=4, apply=None):\n",
        "    if ncols > len(images):\n",
        "        ncols = len(images)\n",
        "    nrows = math.ceil(len(images) / ncols)\n",
        "    N = nrows * ncols\n",
        "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 8), squeeze=False)\n",
        "    axs = axs.ravel()\n",
        "    for i, (image, age) in enumerate(zip(images, ages)):\n",
        "        if i >= N:\n",
        "            break\n",
        "        image = image.numpy().astype('uint8')\n",
        "        if apply is not None:\n",
        "            image = apply(batchify(image))[0]\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(age)\n",
        "        axs[i].axis(\"off\")"
      ],
      "metadata": {
        "id": "ehEV4TPVQZmr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    inputs,\n",
        "    num_of_conv_layers_per_block: int,\n",
        "    num_of_blocks: int,\n",
        "    initial_filter: int,\n",
        "    num_of_hidden_layers: int,\n",
        "    neurons_per_hidden_layer: int, \n",
        "    dense_activation: str,\n",
        "    output_activation: str,\n",
        "    dropout: Optional[float] = None,\n",
        "    # se o número de filtros é constante ou dobra a cada bloco\n",
        "    fixed_size_filter: bool = False,\n",
        "    use_batch_normalization = False,\n",
        "    last_dense_neurons_count = 1,\n",
        "):\n",
        "    dropout = None if dropout == 0 else dropout\n",
        "\n",
        "    KERNEL_SIZE = 3\n",
        "    CONV_ACTIVATION = 'relu'\n",
        "    CONV_PADDING = 'same'\n",
        "    POOL_SIZE = 2\n",
        "    BATCH_INPUT_SHAPE = (*IMAGE_SIZE, 3)\n",
        "\n",
        "    x = preprocess(inputs)\n",
        "\n",
        "    all_blocks = []\n",
        "    filters = initial_filter\n",
        "    for i in range(num_of_blocks):\n",
        "        block = []\n",
        "        if i == 0:\n",
        "            block.append(layers.Conv2D(\n",
        "                filters=8,\n",
        "                kernel_size=5,\n",
        "                padding=CONV_PADDING,\n",
        "                batch_input_shape=BATCH_INPUT_SHAPE,\n",
        "                activation=CONV_ACTIVATION\n",
        "            ))\n",
        "        block += [\n",
        "            layers.Conv2D(\n",
        "                filters,\n",
        "                KERNEL_SIZE,\n",
        "                padding=CONV_PADDING,\n",
        "                batch_input_shape=BATCH_INPUT_SHAPE,\n",
        "                activation=CONV_ACTIVATION\n",
        "            )\n",
        "            for j in range(num_of_conv_layers_per_block)\n",
        "        ]\n",
        "        if use_batch_normalization:\n",
        "            block.append(layers.BatchNormalization())\n",
        "        block.append(layers.MaxPooling2D(pool_size=POOL_SIZE))\n",
        "\n",
        "        all_blocks.append(block)\n",
        "        if not fixed_size_filter:\n",
        "            filters *= 2\n",
        "    \n",
        "    for block in all_blocks:\n",
        "        for layer in block:\n",
        "            x = layer(x)\n",
        "    \n",
        "    \n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    for i in range(num_of_hidden_layers):\n",
        "        x = layers.Dense(neurons_per_hidden_layer, activation=dense_activation)(x)\n",
        "        if dropout is not None:\n",
        "            x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(last_dense_neurons_count, activation=output_activation)(x)\n",
        "        \n",
        "    return keras.models.Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "-bK9VJpcQav_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_hyperparameters(count: int, seed: int = 3621263):\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "    for i in range(count):\n",
        "        dropout = rng.choice([0, 0.1, 0.5])\n",
        "        batch_normalization = rng.choice([False, True])\n",
        "        yield {\n",
        "            'num_of_conv_layers_per_block': rng.choice([1, 2, 3]),\n",
        "            'num_of_blocks': rng.choice([1, 2, 3]),\n",
        "            'num_of_hidden_layers': rng.choice([1, 2, 3]),\n",
        "            'neurons_per_hidden_layer': rng.choice([16, 32, 64, 128, 256]),\n",
        "            'initial_filter': rng.choice([8, 16, 32, 64]),\n",
        "            'dropout': dropout,\n",
        "            'fixed_size_filter': rng.choice([False, True]),\n",
        "            'use_batch_normalization': batch_normalization,\n",
        "            'dense_activation': rng.choice(['tanh', 'relu']),\n",
        "        }\n",
        "\n",
        "list(get_random_hyperparameters(2, seed=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ_1RycJQbzg",
        "outputId": "67b48968-6a83-472b-eea5-8ca6bd065195"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'dense_activation': 'tanh',\n",
              "  'dropout': 0.1,\n",
              "  'fixed_size_filter': True,\n",
              "  'initial_filter': 64,\n",
              "  'neurons_per_hidden_layer': 16,\n",
              "  'num_of_blocks': 3,\n",
              "  'num_of_conv_layers_per_block': 3,\n",
              "  'num_of_hidden_layers': 1,\n",
              "  'use_batch_normalization': True},\n",
              " {'dense_activation': 'relu',\n",
              "  'dropout': 0.0,\n",
              "  'fixed_size_filter': True,\n",
              "  'initial_filter': 16,\n",
              "  'neurons_per_hidden_layer': 32,\n",
              "  'num_of_blocks': 1,\n",
              "  'num_of_conv_layers_per_block': 2,\n",
              "  'num_of_hidden_layers': 3,\n",
              "  'use_batch_normalization': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_R(model, epochs: int, train_data: tf.data.Dataset, valid_data: tf.data.Dataset):\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = keras.losses.MSE\n",
        "    model.compile(optimizer=optimizer, loss=loss)\n",
        "    return model.fit(train_data, epochs=epochs, validation_data=valid_data)\n"
      ],
      "metadata": {
        "id": "45uPJCIiQcyv"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Losses:\n",
        "    @staticmethod\n",
        "    def RMSE(real: np.ndarray, pred: np.ndarray) -> float:\n",
        "        return np.sqrt(np.mean((real - pred) ** 2))\n",
        "\n",
        "    @staticmethod\n",
        "    def MAE(real: np.ndarray, pred: np.ndarray) -> float:\n",
        "        return np.mean(np.abs(real - pred))\n",
        "    \n",
        "    @staticmethod\n",
        "    def regression(real: np.ndarray, pred: np.ndarray) -> pd.Series:\n",
        "        return pd.Series({\n",
        "            'RMSE': Losses.RMSE(real, pred),\n",
        "            'MAE': Losses.MAE(real, pred),\n",
        "        }, name='losses')"
      ],
      "metadata": {
        "id": "DK6ZfncVQdqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_R = sample_ds_train\n",
        "valid_data_R = sample_ds_valid\n",
        "inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "cAG-uZ_Uq3HM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_R = load_data(all_ages = False, train = True, regression = True, validation_split=0.2, subset='training')\n",
        "# valid_data_R = load_data(all_ages = False, train = True, regression = True, validation_split=0.2, subset='validation')\n",
        "# test_data_R = load_data(all_ages = False, train = False, regression = True)\n",
        "# inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "yV5IdQGGQeuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _hyper = {\n",
        "#     'num_of_conv_layers_per_block': 1,\n",
        "#     'num_of_blocks': 2,\n",
        "#     'num_of_hidden_layers': 1,\n",
        "#     'neurons_per_hidden_layer': 32,\n",
        "#     'initial_filter': 64,\n",
        "#     'dropout': 0,\n",
        "#     'fixed_size_filter': True,\n",
        "#     'use_batch_normalization': False,\n",
        "#     'dense_activation': 'relu'\n",
        "# }\n",
        "\n",
        "# _model = build_model(inputs_R, **_hyper, output_activation = 'sigmoid')\n",
        "# print(_model.summary())\n",
        "# _history = train_model_R(_model, epochs=10, train_data = train_data_R, valid_data = valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfcRl1tQQhOI",
        "outputId": "2cfeaf85-dbe2-4e1b-82b3-d592372199b7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " preprocess (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 128, 128, 8)       608       \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 128, 128, 120)     8760      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 64, 64, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 64, 64, 120)       129720    \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 32, 32, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 32, 32, 120)       129720    \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 30720)             0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 30721     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 299,529\n",
            "Trainable params: 299,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 98ms/step - loss: 0.0906 - val_loss: 0.0876\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 12s 94ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 12s 94ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 12s 93ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 12s 98ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 12s 95ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 12s 92ms/step - loss: 0.0904 - val_loss: 0.0879\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 12s 93ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 12s 96ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 12s 98ms/step - loss: 0.0902 - val_loss: 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomSearch_R(tr, val, model_amount: int = 30, epochs: int = 10, n_folds: int = 5):\n",
        "  models = []\n",
        "  inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')\n",
        "  loss_R = np.ndarray(model_amount)\n",
        "  hyperparams_R = list(get_random_hyperparameters(count=model_amount))\n",
        "  for i in range(model_amount):\n",
        "    print(f\"Hiperparâmetros Selecionados:\\n{hyperparams_R[i]}\")\n",
        "    model_R = build_model(inputs_R, **hyperparams_R[i], output_activation = 'sigmoid')\n",
        "    history_R = train_model_R(model_R, epochs, train_data = tr, valid_data = val)\n",
        "    models.append(model_R)\n",
        "    loss_R[i] = history_R.history['val_loss'][-1]\n",
        "  idx_R = np.argmin(loss_R)\n",
        "  selected_hyperparams = hyperparams_R[idx_R]\n",
        "  return selected_hyperparams, models[idx_R]"
      ],
      "metadata": {
        "id": "VQsYAFf1rff6"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_hyper, selected_model = RandomSearch_R(train_data_R, valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEoh9TgZry8s",
        "outputId": "3455c486-629e-4719-89e8-d721682cbb4f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.1413 - val_loss: 0.0896\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.1027 - val_loss: 0.0906\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 68ms/step - loss: 0.0998 - val_loss: 0.1412\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1007 - val_loss: 0.0884\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0962 - val_loss: 0.0868\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0979 - val_loss: 0.0883\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0981 - val_loss: 0.0958\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0984 - val_loss: 0.0887\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0967 - val_loss: 0.0873\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0957 - val_loss: 0.0924\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 32, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 59ms/step - loss: 0.0904 - val_loss: 0.0876\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0899 - val_loss: 0.0863\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0895 - val_loss: 0.0878\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0898 - val_loss: 0.0865\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0855\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0887 - val_loss: 0.0855\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0881 - val_loss: 0.0855\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0880 - val_loss: 0.0857\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0877 - val_loss: 0.0853\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0876 - val_loss: 0.0848\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 62ms/step - loss: 0.2168 - val_loss: 0.1120\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1430 - val_loss: 0.1000\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.1245 - val_loss: 0.0953\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1114 - val_loss: 0.0921\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1000 - val_loss: 0.0892\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0947 - val_loss: 0.0870\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0919 - val_loss: 0.0868\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0913 - val_loss: 0.0870\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0916 - val_loss: 0.0854\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0910 - val_loss: 0.0863\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 70ms/step - loss: 0.3212 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3326 - val_loss: 0.3298\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3386 - val_loss: 0.3467\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 64, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 84ms/step - loss: 0.1804 - val_loss: 0.1171\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.1076 - val_loss: 0.1036\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.1036 - val_loss: 0.1044\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.1035 - val_loss: 0.0997\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0999 - val_loss: 0.0968\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.0980 - val_loss: 0.0938\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.0941 - val_loss: 0.0914\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0937 - val_loss: 0.0915\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0939 - val_loss: 0.0890\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0923 - val_loss: 0.0878\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.3107 - val_loss: 0.2818\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3182 - val_loss: 0.3085\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3095 - val_loss: 0.3275\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3184 - val_loss: 0.3120\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.3229 - val_loss: 0.3242\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3190 - val_loss: 0.3277\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3159 - val_loss: 0.3258\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3269 - val_loss: 0.3199\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3287 - val_loss: 0.3191\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3233 - val_loss: 0.3184\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 64ms/step - loss: 0.3537 - val_loss: 0.3467\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 65ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 64ms/step - loss: 0.1068 - val_loss: 0.0856\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0900 - val_loss: 0.0853\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0893 - val_loss: 0.0858\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0885 - val_loss: 0.0857\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0889 - val_loss: 0.0849\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0850\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0886 - val_loss: 0.0854\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0885 - val_loss: 0.0862\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0857\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0887 - val_loss: 0.0846\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 59ms/step - loss: 0.1026 - val_loss: 0.1119\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0902 - val_loss: 0.1043\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0894\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0882\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0886\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0913 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 72ms/step - loss: 0.0905 - val_loss: 0.0878\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.0905 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 63ms/step - loss: 0.2245 - val_loss: 0.1379\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1367 - val_loss: 0.1420\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.1205 - val_loss: 0.0974\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1066 - val_loss: 0.0901\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0979 - val_loss: 0.0888\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0933 - val_loss: 0.0889\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0917 - val_loss: 0.0872\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0907 - val_loss: 0.0870\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0904 - val_loss: 0.0872\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0871\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 72ms/step - loss: 0.0971 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0906 - val_loss: 0.0880\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0904 - val_loss: 0.1426\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0891\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 15s 109ms/step - loss: 0.3233 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3314 - val_loss: 0.3289\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3245 - val_loss: 0.3289\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3250 - val_loss: 0.3289\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3261 - val_loss: 0.3289\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 13s 101ms/step - loss: 0.3248 - val_loss: 0.3289\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3253 - val_loss: 0.3289\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3256 - val_loss: 0.3289\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 22s 157ms/step - loss: 0.1046 - val_loss: 0.0910\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0978 - val_loss: 0.0895\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0967 - val_loss: 0.0894\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 19s 148ms/step - loss: 0.0950 - val_loss: 0.0918\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0948 - val_loss: 0.0934\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 19s 150ms/step - loss: 0.0935 - val_loss: 0.0945\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0934 - val_loss: 0.0913\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0921 - val_loss: 0.0885\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0922 - val_loss: 0.0900\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 19s 148ms/step - loss: 0.0924 - val_loss: 0.0876\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 64, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 8s 58ms/step - loss: 0.0939 - val_loss: 0.0882\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0870\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0898 - val_loss: 0.0848\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0892 - val_loss: 0.0840\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0886 - val_loss: 0.0848\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0889 - val_loss: 0.0846\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0882 - val_loss: 0.0849\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0888 - val_loss: 0.0843\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0884 - val_loss: 0.0858\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0880 - val_loss: 0.0849\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 63ms/step - loss: 0.0923 - val_loss: 0.0875\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0895 - val_loss: 0.0872\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0905 - val_loss: 0.0875\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0904 - val_loss: 0.0876\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0897 - val_loss: 0.0871\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0899 - val_loss: 0.0857\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0887 - val_loss: 0.1375\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0892 - val_loss: 0.0862\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0882 - val_loss: 0.0881\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0883 - val_loss: 0.0837\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 70ms/step - loss: 0.1274 - val_loss: 0.0924\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.1001 - val_loss: 0.2501\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0951 - val_loss: 0.0892\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0936 - val_loss: 0.0896\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0919 - val_loss: 0.0931\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0921 - val_loss: 0.0976\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0916 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0903 - val_loss: 0.0867\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0898 - val_loss: 0.0931\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.1148 - val_loss: 0.0883\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0914 - val_loss: 0.0883\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0913 - val_loss: 0.0883\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.0912 - val_loss: 0.0883\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0910 - val_loss: 0.0883\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0909 - val_loss: 0.0884\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0909 - val_loss: 0.0884\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0908 - val_loss: 0.0885\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0908 - val_loss: 0.0885\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0907 - val_loss: 0.0886\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 14s 105ms/step - loss: 0.3361 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3353 - val_loss: 0.3244\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3446 - val_loss: 0.3383\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3345 - val_loss: 0.3260\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3261 - val_loss: 0.3297\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3280 - val_loss: 0.3301\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3184 - val_loss: 0.3317\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3228 - val_loss: 0.3310\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3235 - val_loss: 0.3304\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3224 - val_loss: 0.3246\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 72ms/step - loss: 0.0914 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0870\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0878\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 83ms/step - loss: 0.0940 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0899 - val_loss: 0.0868\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0895 - val_loss: 0.0865\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0893 - val_loss: 0.0870\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0894 - val_loss: 0.0864\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0890 - val_loss: 0.0865\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0885 - val_loss: 0.0871\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 0.0891 - val_loss: 0.0856\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0886 - val_loss: 0.0861\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 20s 151ms/step - loss: 0.1159 - val_loss: 0.0963\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.1012 - val_loss: 0.0967\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0984 - val_loss: 0.0949\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0957 - val_loss: 0.0946\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0958 - val_loss: 0.0942\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0944 - val_loss: 0.0943\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0941 - val_loss: 0.0923\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0924 - val_loss: 0.0897\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0915 - val_loss: 0.0887\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0915 - val_loss: 0.0891\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 62ms/step - loss: 0.0923 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0869\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0868\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0899 - val_loss: 0.0861\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0899 - val_loss: 0.0859\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0898 - val_loss: 0.0862\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0897 - val_loss: 0.0868\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0897 - val_loss: 0.0860\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0890 - val_loss: 0.0846\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0896 - val_loss: 0.0844\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.0914 - val_loss: 0.0880\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0878\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0904 - val_loss: 0.0879\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 79ms/step - loss: 0.1169 - val_loss: 0.0912\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.1027 - val_loss: 0.0922\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.1017 - val_loss: 0.0901\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0978 - val_loss: 0.0925\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0978 - val_loss: 0.0952\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0951 - val_loss: 0.0914\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0966 - val_loss: 0.1005\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0939 - val_loss: 0.0929\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0929 - val_loss: 0.0964\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0914 - val_loss: 0.0910\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 61ms/step - loss: 0.3250 - val_loss: 0.3426\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.3461 - val_loss: 0.3337\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3419 - val_loss: 0.3306\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3316 - val_loss: 0.3231\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.3315 - val_loss: 0.3299\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3256 - val_loss: 0.3285\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3250 - val_loss: 0.3294\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3320 - val_loss: 0.3326\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.3217 - val_loss: 0.3289\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 16s 114ms/step - loss: 0.1113 - val_loss: 0.0873\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.1143 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.1093 - val_loss: 0.1008\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.1044 - val_loss: 0.0950\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 14s 111ms/step - loss: 0.1037 - val_loss: 0.0920\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0986 - val_loss: 0.0901\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0977 - val_loss: 0.0915\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0974 - val_loss: 0.0917\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0955 - val_loss: 0.0903\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0928 - val_loss: 0.0884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model.save('savedmodel')\n",
        "!zip -r savedmodel.zip savedmodel\n",
        "from google.colab import files\n",
        "files.download('savedmodel.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "DrgMH3uzsQ6W",
        "outputId": "41fbfaf6-65a6-4298-f79f-67af87d9a1ac"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: savedmodel/assets\n",
            "  adding: savedmodel/ (stored 0%)\n",
            "  adding: savedmodel/assets/ (stored 0%)\n",
            "  adding: savedmodel/keras_metadata.pb (deflated 93%)\n",
            "  adding: savedmodel/variables/ (stored 0%)\n",
            "  adding: savedmodel/variables/variables.data-00000-of-00001 (deflated 28%)\n",
            "  adding: savedmodel/variables/variables.index (deflated 70%)\n",
            "  adding: savedmodel/saved_model.pb (deflated 90%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49197e18-213c-488a-bc95-74c51ff92edd\", \"savedmodel.zip\", 4626511)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_model.summary())\n",
        "_history = train_model_R(selected_model, epochs=40, train_data = train_data_R, valid_data = valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei89IKJ73t-k",
        "outputId": "566ad6c9-c38c-44ee-f3da-ee17dac8e8b9"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " preprocess (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 128, 128, 8)       608       \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 128, 128, 8)       584       \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 128, 128, 8)       584       \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 128, 128, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPoolin  (None, 64, 64, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 16)                524304    \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 526,401\n",
            "Trainable params: 526,385\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.0898 - val_loss: 0.0878\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0896 - val_loss: 0.0869\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0894 - val_loss: 0.0874\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0889 - val_loss: 0.0842\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0889 - val_loss: 0.0879\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0892 - val_loss: 0.1088\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0887 - val_loss: 0.0849\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0892 - val_loss: 0.1115\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0884 - val_loss: 0.0863\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0883 - val_loss: 0.0840\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0887 - val_loss: 0.0970\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0878 - val_loss: 0.0869\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0886 - val_loss: 0.0926\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0880 - val_loss: 0.0834\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0883 - val_loss: 0.0923\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0878 - val_loss: 0.0901\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0881 - val_loss: 0.0834\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0884 - val_loss: 0.0827\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0868 - val_loss: 0.0849\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0874 - val_loss: 0.0848\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0838\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0877 - val_loss: 0.2065\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0877\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0859\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0876 - val_loss: 0.0888\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0873 - val_loss: 0.0871\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0879 - val_loss: 0.0892\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0869 - val_loss: 0.0883\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0875 - val_loss: 0.0828\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0877 - val_loss: 0.0837\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0870 - val_loss: 0.0870\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0868 - val_loss: 0.0837\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0869 - val_loss: 0.0819\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0872 - val_loss: 0.0835\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.0874 - val_loss: 0.0876\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0875 - val_loss: 0.0836\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0864 - val_loss: 0.0825\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0874 - val_loss: 0.0821\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0879 - val_loss: 0.1136\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0880 - val_loss: 0.0899\n"
          ]
        }
      ]
    }
  ]
}