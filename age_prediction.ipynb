{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reg-age-prediction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRBHwiFJNSXOU5HH2JHDb9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAhQV2FjQIkm"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "# !chmod 600 '/content/kaggle.json'\n",
        "# !kaggle datasets download -d mariafrenti/age-prediction\n",
        "# !unzip -q age-prediction.zip\n",
        "# !rm age-prediction.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1001\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "# Typings\n",
        "from typing import Tuple, Callable, List, Union, Dict, Iterable, Iterator, Optional\n",
        "from tensorflow.python.data.ops.dataset_ops import BatchDataset\n",
        "import functools\n",
        "\n",
        "# Padronizando a aleatoriedade\n",
        "rng = np.random.default_rng(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "python_random.seed(SEED)"
      ],
      "metadata": {
        "id": "s1D4ImkeQQNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_OF_COLOR_CHANNELS = 3\n",
        "IMAGE_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "INPUT_SHAPE = (*IMAGE_SIZE, NUM_OF_COLOR_CHANNELS)\n",
        "BATCH_INPUT_SHAPE = (None, *INPUT_SHAPE)\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com base nos arquivos dos diretórios.\n",
        "    - path: caminho base para as pastas\n",
        "'''\n",
        "def _load_data(path: str, subset: str = None, validation_split: float = None) -> tf.data.Dataset:\n",
        "    return keras.preprocessing.image_dataset_from_directory(\n",
        "        path,\n",
        "        seed=SEED,\n",
        "        validation_split=validation_split,\n",
        "        subset=subset,\n",
        "        image_size=IMAGE_SIZE,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "    )\n",
        "_20to50_dir = \"20-50/20-50\"\n",
        "_1to100_dir = \"age_prediction_up/age_prediction\"\n",
        "\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com as imagens e labels já apropriados para treinamento\n",
        "    - all_ages: se deve ser usado o diretório com idades de 1 a 100\n",
        "    - train: se deve ser usado o conjunto de treino\n",
        "    (será usado teste caso contrário)\n",
        "    - regression: se os labels devem ser transformados para tarefas de regressão\n",
        "    (será transformado para classificação caso contrário)\n",
        "'''\n",
        "def load_data(all_ages: bool, train: bool, regression: bool, subset: str = None, validation_split: float = None) -> tf.data.Dataset:\n",
        "    base_dir = _1to100_dir if all_ages else _20to50_dir\n",
        "    folder = \"train\" if train else \"test\"\n",
        "    age_count = 100 if all_ages else 31\n",
        "    data = _load_data(f\"{base_dir}/{folder}\", subset, validation_split)\n",
        "    if regression:\n",
        "        return data.map(lambda x, y: (x, y / (age_count - 1)))\n",
        "    return data.map(lambda x, y: (x, tf.one_hot(y, depth=age_count)))"
      ],
      "metadata": {
        "id": "w5FrxKPlQRx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob2 import glob\n",
        "\n",
        "''' Retorna uma np.ndarray com todos os caminhos até as imagens '''\n",
        "def get_image_paths(all_ages: bool, train: bool) -> np.ndarray:\n",
        "    base_dir = _1to100_dir if all_ages else _20to50_dir\n",
        "    folder = \"train\" if train else \"test\"\n",
        "    return np.array(sorted(glob(f'{base_dir}/{folder}/*/*.jpg')))\n",
        "\n",
        "'''\n",
        "    Retorna a imagem e o label associado a um caminho.\n",
        "    O label já é transformado apropriadamente\n",
        "'''\n",
        "def load_image(path: str, regression: bool):\n",
        "    parts = path.split(os.sep)\n",
        "    age = int(parts[3])\n",
        "    all_ages = parts[0] != '20-50'\n",
        "    age_count = 100 if all_ages else 31\n",
        "    offset = 1 if all_ages else 20\n",
        "    if regression:\n",
        "        label = tf.convert_to_tensor((age - offset) / (age_count - 1))\n",
        "    else:\n",
        "        label = tf.one_hot(age - offset, depth=age_count)\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    return image, label\n",
        "\n",
        "'''\n",
        "    Retorna um gerador que pode ser usado para iterar por todas as imagens\n",
        "    nos caminhos especificados.\n",
        "    Construa um Dataset com tf.data.Dataset.from_generator\n",
        "'''\n",
        "def build_images_generator(paths: List[str], regression: bool):\n",
        "    def gen():\n",
        "        i = 0\n",
        "        num_of_files = len(paths)\n",
        "        while i < num_of_files:\n",
        "            yield load_image(paths[i], regression)\n",
        "            i += 1\n",
        "    return gen\n",
        "\n",
        "'''\n",
        "    Retorna um Dataset com todas as imagens e seus respectivos labels (já transformados)\n",
        "\n",
        "'''\n",
        "def build_ds_from_paths(paths: List[str], regression: bool, batch_size=BATCH_SIZE) -> tf.data.Dataset:\n",
        "    all_ages = paths[0].split(os.sep)[0] != '20-50'\n",
        "    age_count = 100 if all_ages else 31\n",
        "    label_shape = () if regression else (age_count,)\n",
        "    input_shape = INPUT_SHAPE\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        build_images_generator(paths, regression),\n",
        "        output_types=(tf.uint8, tf.float32), \n",
        "        output_shapes=(input_shape, label_shape),\n",
        "    ).batch(BATCH_SIZE)\n",
        "\n",
        "def build_ds_from_index(index: List[int], all_ages: bool, train: bool, regression: bool, batch_size=BATCH_SIZE) -> tf.data.Dataset:\n",
        "    paths = get_image_paths(all_ages, train)[index]\n",
        "    return build_ds_from_paths(paths, regression, batch_size)\n",
        "\n",
        "'''\n",
        "    Mapeia labels ou predições, que são valores em [0, 1], para idades.\n",
        "    Na classificação, há codificação one-hot\n",
        "\n",
        "    A idade retornada na classificação é aquela associada à classe\n",
        "    com maior propabilidade.\n",
        "'''\n",
        "def map_to_ages(labels, all_ages: bool, regression: bool):\n",
        "    scale = (99 if all_ages else 30) if regression else 1\n",
        "    offset = 1 if all_ages else 20\n",
        "    if not regression:\n",
        "        labels = np.argmax(labels, axis=-1)\n",
        "    return labels * scale + offset"
      ],
      "metadata": {
        "id": "TTRlbaT_QTl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 5000\n",
        "validation_split = 0.2\n",
        "\n",
        "train_paths = get_image_paths(all_ages=False, train=True)\n",
        "train_paths_sample = np.random.choice(train_paths, SAMPLE_SIZE)\n",
        "\n",
        "tr_paths, valid_paths = train_test_split(train_paths_sample, test_size=0.2)\n",
        "\n",
        "sample_ds_train = build_ds_from_paths(tr_paths, regression=True)\n",
        "sample_ds_valid = build_ds_from_paths(valid_paths, regression=True)"
      ],
      "metadata": {
        "id": "fj7DuMfRn6Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_only_normalization = keras.Sequential([\n",
        "    layers.Rescaling(1./255, batch_input_shape=BATCH_INPUT_SHAPE)\n",
        "], name='only_normalization')\n",
        "preprocess = keras.Sequential(\n",
        "    [\n",
        "        layers.Resizing(*IMAGE_SIZE, batch_input_shape=BATCH_INPUT_SHAPE),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomTranslation(0.1, 0.1),\n",
        "        layers.RandomZoom(0.1, 0.1),\n",
        "        layers.RandomContrast(0.1),\n",
        "        _only_normalization,\n",
        "    ], name='preprocess'\n",
        ")"
      ],
      "metadata": {
        "id": "uy_-4rBBQYOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batchify(image: np.ndarray) -> np.ndarray:\n",
        "    if len(image.shape) == len(INPUT_SHAPE):\n",
        "        # o modelo (incluindo pré-processamento) espera a entrada em mini-batches\n",
        "        # caso uma única imagem seja passada, modificamos seu formato\n",
        "        # para 1 batch de 1 imagem\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "    return image\n",
        "\n",
        "'''\n",
        "    Exibe uma image.\n",
        "'''\n",
        "def plot_single_image(image: np.ndarray, age: Optional[int] = None, apply=None):\n",
        "    if apply is not None:\n",
        "        image = apply(batchify(image))[0]\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(image)\n",
        "    if age is not None:\n",
        "        ax.set_title(age)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "def plot_samples(images, ages: Iterable[int], ncols=4, apply=None):\n",
        "    if ncols > len(images):\n",
        "        ncols = len(images)\n",
        "    nrows = math.ceil(len(images) / ncols)\n",
        "    N = nrows * ncols\n",
        "    fig, axs = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 8), squeeze=False)\n",
        "    axs = axs.ravel()\n",
        "    for i, (image, age) in enumerate(zip(images, ages)):\n",
        "        if i >= N:\n",
        "            break\n",
        "        image = image.numpy().astype('uint8')\n",
        "        if apply is not None:\n",
        "            image = apply(batchify(image))[0]\n",
        "        axs[i].imshow(image)\n",
        "        axs[i].set_title(age)\n",
        "        axs[i].axis(\"off\")"
      ],
      "metadata": {
        "id": "ehEV4TPVQZmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(\n",
        "    inputs,\n",
        "    num_of_conv_layers_per_block: int,\n",
        "    num_of_blocks: int,\n",
        "    initial_filter: int,\n",
        "    num_of_hidden_layers: int,\n",
        "    neurons_per_hidden_layer: int, \n",
        "    dense_activation: str,\n",
        "    output_activation: str,\n",
        "    dropout: Optional[float] = None,\n",
        "    # se o número de filtros é constante ou dobra a cada bloco\n",
        "    fixed_size_filter: bool = False,\n",
        "    use_batch_normalization = False,\n",
        "    last_dense_neurons_count = 1,\n",
        "):\n",
        "    dropout = None if dropout == 0 else dropout\n",
        "\n",
        "    KERNEL_SIZE = 3\n",
        "    CONV_ACTIVATION = 'relu'\n",
        "    CONV_PADDING = 'same'\n",
        "    POOL_SIZE = 2\n",
        "    BATCH_INPUT_SHAPE = (*IMAGE_SIZE, 3)\n",
        "\n",
        "    x = preprocess(inputs)\n",
        "\n",
        "    all_blocks = []\n",
        "    filters = initial_filter\n",
        "    for i in range(num_of_blocks):\n",
        "        block = []\n",
        "        if i == 0:\n",
        "            block.append(layers.Conv2D(\n",
        "                filters=8,\n",
        "                kernel_size=5,\n",
        "                padding=CONV_PADDING,\n",
        "                batch_input_shape=BATCH_INPUT_SHAPE,\n",
        "                activation=CONV_ACTIVATION\n",
        "            ))\n",
        "        block += [\n",
        "            layers.Conv2D(\n",
        "                filters,\n",
        "                KERNEL_SIZE,\n",
        "                padding=CONV_PADDING,\n",
        "                batch_input_shape=BATCH_INPUT_SHAPE,\n",
        "                activation=CONV_ACTIVATION\n",
        "            )\n",
        "            for j in range(num_of_conv_layers_per_block)\n",
        "        ]\n",
        "        if use_batch_normalization:\n",
        "            block.append(layers.BatchNormalization())\n",
        "        block.append(layers.MaxPooling2D(pool_size=POOL_SIZE))\n",
        "\n",
        "        all_blocks.append(block)\n",
        "        if not fixed_size_filter:\n",
        "            filters *= 2\n",
        "    \n",
        "    for block in all_blocks:\n",
        "        for layer in block:\n",
        "            x = layer(x)\n",
        "    \n",
        "    \n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    for i in range(num_of_hidden_layers):\n",
        "        x = layers.Dense(neurons_per_hidden_layer, activation=dense_activation)(x)\n",
        "        if dropout is not None:\n",
        "            x = layers.Dropout(dropout)(x)\n",
        "\n",
        "    x = layers.Dense(last_dense_neurons_count, activation=output_activation)(x)\n",
        "        \n",
        "    return keras.models.Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "-bK9VJpcQav_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_hyperparameters(count: int, seed: int = 3621263):\n",
        "    rng = np.random.default_rng(seed=seed)\n",
        "    for i in range(count):\n",
        "        dropout = rng.choice([0, 0.1, 0.5])\n",
        "        batch_normalization = rng.choice([False, True])\n",
        "        yield {\n",
        "            'num_of_conv_layers_per_block': rng.choice([1, 2, 3]),\n",
        "            'num_of_blocks': rng.choice([1, 2, 3]),\n",
        "            'num_of_hidden_layers': rng.choice([1, 2, 3]),\n",
        "            'neurons_per_hidden_layer': rng.choice([16, 32, 64, 128, 256]),\n",
        "            'initial_filter': rng.choice([8, 16, 32, 64]),\n",
        "            'dropout': dropout,\n",
        "            'fixed_size_filter': rng.choice([False, True]),\n",
        "            'use_batch_normalization': batch_normalization,\n",
        "            'dense_activation': rng.choice(['tanh', 'relu']),\n",
        "        }\n",
        "\n",
        "list(get_random_hyperparameters(2, seed=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJ_1RycJQbzg",
        "outputId": "67b48968-6a83-472b-eea5-8ca6bd065195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'dense_activation': 'tanh',\n",
              "  'dropout': 0.1,\n",
              "  'fixed_size_filter': True,\n",
              "  'initial_filter': 64,\n",
              "  'neurons_per_hidden_layer': 16,\n",
              "  'num_of_blocks': 3,\n",
              "  'num_of_conv_layers_per_block': 3,\n",
              "  'num_of_hidden_layers': 1,\n",
              "  'use_batch_normalization': True},\n",
              " {'dense_activation': 'relu',\n",
              "  'dropout': 0.0,\n",
              "  'fixed_size_filter': True,\n",
              "  'initial_filter': 16,\n",
              "  'neurons_per_hidden_layer': 32,\n",
              "  'num_of_blocks': 1,\n",
              "  'num_of_conv_layers_per_block': 2,\n",
              "  'num_of_hidden_layers': 3,\n",
              "  'use_batch_normalization': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_R(model, epochs: int, train_data: tf.data.Dataset, valid_data: tf.data.Dataset):\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = keras.losses.MSE\n",
        "    model.compile(optimizer=optimizer, loss=loss)\n",
        "    return model.fit(train_data, epochs=epochs, validation_data=valid_data)\n"
      ],
      "metadata": {
        "id": "45uPJCIiQcyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Losses:\n",
        "    @staticmethod\n",
        "    def RMSE(real: np.ndarray, pred: np.ndarray) -> float:\n",
        "        return np.sqrt(np.mean((real - pred) ** 2))\n",
        "\n",
        "    @staticmethod\n",
        "    def MAE(real: np.ndarray, pred: np.ndarray) -> float:\n",
        "        return np.mean(np.abs(real - pred))\n",
        "    \n",
        "    @staticmethod\n",
        "    def regression(real: np.ndarray, pred: np.ndarray) -> pd.Series:\n",
        "        return pd.Series({\n",
        "            'RMSE': Losses.RMSE(real, pred),\n",
        "            'MAE': Losses.MAE(real, pred),\n",
        "        }, name='losses')"
      ],
      "metadata": {
        "id": "DK6ZfncVQdqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_R = sample_ds_train\n",
        "valid_data_R = sample_ds_valid\n",
        "inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "cAG-uZ_Uq3HM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data_R = load_data(all_ages = False, train = True, regression = True, validation_split=0.2, subset='training')\n",
        "# valid_data_R = load_data(all_ages = False, train = True, regression = True, validation_split=0.2, subset='validation')\n",
        "# test_data_R = load_data(all_ages = False, train = False, regression = True)\n",
        "# inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "yV5IdQGGQeuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# _hyper = {\n",
        "#     'num_of_conv_layers_per_block': 1,\n",
        "#     'num_of_blocks': 2,\n",
        "#     'num_of_hidden_layers': 1,\n",
        "#     'neurons_per_hidden_layer': 32,\n",
        "#     'initial_filter': 64,\n",
        "#     'dropout': 0,\n",
        "#     'fixed_size_filter': True,\n",
        "#     'use_batch_normalization': False,\n",
        "#     'dense_activation': 'relu'\n",
        "# }\n",
        "\n",
        "# _model = build_model(inputs_R, **_hyper, output_activation = 'sigmoid')\n",
        "# print(_model.summary())\n",
        "# _history = train_model_R(_model, epochs=10, train_data = train_data_R, valid_data = valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfcRl1tQQhOI",
        "outputId": "2cfeaf85-dbe2-4e1b-82b3-d592372199b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " preprocess (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 128, 128, 8)       608       \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 128, 128, 120)     8760      \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 64, 64, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 64, 64, 120)       129720    \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 32, 32, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_35 (Conv2D)          (None, 32, 32, 120)       129720    \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 120)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 30720)             0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 30721     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 299,529\n",
            "Trainable params: 299,529\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 98ms/step - loss: 0.0906 - val_loss: 0.0876\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 12s 94ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 12s 94ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 12s 93ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 12s 98ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 12s 95ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 12s 92ms/step - loss: 0.0904 - val_loss: 0.0879\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 12s 93ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 12s 96ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 12s 98ms/step - loss: 0.0902 - val_loss: 0.0876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomSearch_R(tr, val, model_amount: int = 30, epochs: int = 10, n_folds: int = 5):\n",
        "  models = []\n",
        "  inputs_R = layers.Input(shape=(None, None, 3), dtype='uint8')\n",
        "  loss_R = np.ndarray(model_amount)\n",
        "  hyperparams_R = list(get_random_hyperparameters(count=model_amount))\n",
        "  for i in range(model_amount):\n",
        "    print(f\"Hiperparâmetros Selecionados:\\n{hyperparams_R[i]}\")\n",
        "    model_R = build_model(inputs_R, **hyperparams_R[i], output_activation = 'sigmoid')\n",
        "    history_R = train_model_R(model_R, epochs, train_data = tr, valid_data = val)\n",
        "    models.append(model_R)\n",
        "    loss_R[i] = history_R.history['val_loss'][-1]\n",
        "  idx_R = np.argmin(loss_R)\n",
        "  selected_hyperparams = hyperparams_R[idx_R]\n",
        "  return selected_hyperparams, models[idx_R]"
      ],
      "metadata": {
        "id": "VQsYAFf1rff6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_hyper, selected_model = RandomSearch_R(train_data_R, valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEoh9TgZry8s",
        "outputId": "3455c486-629e-4719-89e8-d721682cbb4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.1413 - val_loss: 0.0896\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.1027 - val_loss: 0.0906\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 68ms/step - loss: 0.0998 - val_loss: 0.1412\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1007 - val_loss: 0.0884\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0962 - val_loss: 0.0868\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0979 - val_loss: 0.0883\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0981 - val_loss: 0.0958\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0984 - val_loss: 0.0887\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0967 - val_loss: 0.0873\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0957 - val_loss: 0.0924\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 32, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 59ms/step - loss: 0.0904 - val_loss: 0.0876\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0899 - val_loss: 0.0863\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0895 - val_loss: 0.0878\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0898 - val_loss: 0.0865\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0855\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0887 - val_loss: 0.0855\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0881 - val_loss: 0.0855\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0880 - val_loss: 0.0857\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0877 - val_loss: 0.0853\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0876 - val_loss: 0.0848\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 62ms/step - loss: 0.2168 - val_loss: 0.1120\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1430 - val_loss: 0.1000\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.1245 - val_loss: 0.0953\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1114 - val_loss: 0.0921\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.1000 - val_loss: 0.0892\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0947 - val_loss: 0.0870\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0919 - val_loss: 0.0868\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0913 - val_loss: 0.0870\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0916 - val_loss: 0.0854\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.0910 - val_loss: 0.0863\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 70ms/step - loss: 0.3212 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3326 - val_loss: 0.3298\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3386 - val_loss: 0.3467\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 64, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 84ms/step - loss: 0.1804 - val_loss: 0.1171\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.1076 - val_loss: 0.1036\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.1036 - val_loss: 0.1044\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.1035 - val_loss: 0.0997\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0999 - val_loss: 0.0968\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.0980 - val_loss: 0.0938\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 0.0941 - val_loss: 0.0914\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0937 - val_loss: 0.0915\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0939 - val_loss: 0.0890\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 0.0923 - val_loss: 0.0878\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 65ms/step - loss: 0.3107 - val_loss: 0.2818\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3182 - val_loss: 0.3085\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3095 - val_loss: 0.3275\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3184 - val_loss: 0.3120\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.3229 - val_loss: 0.3242\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3190 - val_loss: 0.3277\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3159 - val_loss: 0.3258\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3269 - val_loss: 0.3199\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3287 - val_loss: 0.3191\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3233 - val_loss: 0.3184\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 64ms/step - loss: 0.3537 - val_loss: 0.3467\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.3552 - val_loss: 0.3467\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 65ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 64ms/step - loss: 0.1068 - val_loss: 0.0856\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0900 - val_loss: 0.0853\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0893 - val_loss: 0.0858\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0885 - val_loss: 0.0857\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0889 - val_loss: 0.0849\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0850\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0886 - val_loss: 0.0854\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0885 - val_loss: 0.0862\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0884 - val_loss: 0.0857\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0887 - val_loss: 0.0846\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 59ms/step - loss: 0.1026 - val_loss: 0.1119\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.0902 - val_loss: 0.1043\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0902 - val_loss: 0.0894\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0882\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0886\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0913 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 72ms/step - loss: 0.0905 - val_loss: 0.0878\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.0905 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 63ms/step - loss: 0.2245 - val_loss: 0.1379\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1367 - val_loss: 0.1420\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.1205 - val_loss: 0.0974\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.1066 - val_loss: 0.0901\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0979 - val_loss: 0.0888\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0933 - val_loss: 0.0889\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0917 - val_loss: 0.0872\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0907 - val_loss: 0.0870\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0904 - val_loss: 0.0872\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0871\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 67ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 72ms/step - loss: 0.0971 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 71ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0906 - val_loss: 0.0880\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0904 - val_loss: 0.1426\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0891\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 15s 109ms/step - loss: 0.3233 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3314 - val_loss: 0.3289\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3245 - val_loss: 0.3289\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3250 - val_loss: 0.3289\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3261 - val_loss: 0.3289\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 13s 101ms/step - loss: 0.3248 - val_loss: 0.3289\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3253 - val_loss: 0.3289\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3256 - val_loss: 0.3289\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 22s 157ms/step - loss: 0.1046 - val_loss: 0.0910\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0978 - val_loss: 0.0895\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0967 - val_loss: 0.0894\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 19s 148ms/step - loss: 0.0950 - val_loss: 0.0918\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 19s 149ms/step - loss: 0.0948 - val_loss: 0.0934\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 19s 150ms/step - loss: 0.0935 - val_loss: 0.0945\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0934 - val_loss: 0.0913\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0921 - val_loss: 0.0885\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 18s 148ms/step - loss: 0.0922 - val_loss: 0.0900\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 19s 148ms/step - loss: 0.0924 - val_loss: 0.0876\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 64, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 8s 58ms/step - loss: 0.0939 - val_loss: 0.0882\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0902 - val_loss: 0.0870\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0898 - val_loss: 0.0848\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0892 - val_loss: 0.0840\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0886 - val_loss: 0.0848\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0889 - val_loss: 0.0846\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0882 - val_loss: 0.0849\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0888 - val_loss: 0.0843\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0884 - val_loss: 0.0858\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0880 - val_loss: 0.0849\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 63ms/step - loss: 0.0923 - val_loss: 0.0875\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0895 - val_loss: 0.0872\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0905 - val_loss: 0.0875\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0904 - val_loss: 0.0876\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0897 - val_loss: 0.0871\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0899 - val_loss: 0.0857\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0887 - val_loss: 0.1375\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0892 - val_loss: 0.0862\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0882 - val_loss: 0.0881\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0883 - val_loss: 0.0837\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 70ms/step - loss: 0.1274 - val_loss: 0.0924\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.1001 - val_loss: 0.2501\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0951 - val_loss: 0.0892\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0936 - val_loss: 0.0896\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0919 - val_loss: 0.0931\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0921 - val_loss: 0.0976\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0916 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0903 - val_loss: 0.0867\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0898 - val_loss: 0.0931\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.1148 - val_loss: 0.0883\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0914 - val_loss: 0.0883\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0913 - val_loss: 0.0883\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.0912 - val_loss: 0.0883\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0910 - val_loss: 0.0883\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0909 - val_loss: 0.0884\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0909 - val_loss: 0.0884\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0908 - val_loss: 0.0885\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0908 - val_loss: 0.0885\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0907 - val_loss: 0.0886\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 14s 105ms/step - loss: 0.3361 - val_loss: 0.3289\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3353 - val_loss: 0.3244\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3446 - val_loss: 0.3383\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3345 - val_loss: 0.3260\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3261 - val_loss: 0.3297\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3280 - val_loss: 0.3301\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3184 - val_loss: 0.3317\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 13s 103ms/step - loss: 0.3228 - val_loss: 0.3310\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 13s 104ms/step - loss: 0.3235 - val_loss: 0.3304\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 13s 102ms/step - loss: 0.3224 - val_loss: 0.3246\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 72ms/step - loss: 0.0914 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0870\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0903 - val_loss: 0.0878\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 69ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0902 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 83ms/step - loss: 0.0940 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0902 - val_loss: 0.0878\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0899 - val_loss: 0.0868\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0895 - val_loss: 0.0865\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0893 - val_loss: 0.0870\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0894 - val_loss: 0.0864\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 0.0890 - val_loss: 0.0865\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0885 - val_loss: 0.0871\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 0.0891 - val_loss: 0.0856\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0886 - val_loss: 0.0861\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 20s 151ms/step - loss: 0.1159 - val_loss: 0.0963\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.1012 - val_loss: 0.0967\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0984 - val_loss: 0.0949\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0957 - val_loss: 0.0946\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0958 - val_loss: 0.0942\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0944 - val_loss: 0.0943\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0941 - val_loss: 0.0923\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0924 - val_loss: 0.0897\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0915 - val_loss: 0.0887\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 18s 147ms/step - loss: 0.0915 - val_loss: 0.0891\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 62ms/step - loss: 0.0923 - val_loss: 0.0877\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0869\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0868\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0899 - val_loss: 0.0861\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0899 - val_loss: 0.0859\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0898 - val_loss: 0.0862\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0897 - val_loss: 0.0868\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0897 - val_loss: 0.0860\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0890 - val_loss: 0.0846\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 64ms/step - loss: 0.0896 - val_loss: 0.0844\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.0914 - val_loss: 0.0880\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0904 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0878\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0904 - val_loss: 0.0879\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 8s 63ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 62ms/step - loss: 0.0903 - val_loss: 0.0877\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 79ms/step - loss: 0.1169 - val_loss: 0.0912\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.1027 - val_loss: 0.0922\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.1017 - val_loss: 0.0901\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0978 - val_loss: 0.0925\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0978 - val_loss: 0.0952\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0951 - val_loss: 0.0914\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0966 - val_loss: 0.1005\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0939 - val_loss: 0.0929\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0929 - val_loss: 0.0964\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0914 - val_loss: 0.0910\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 9s 61ms/step - loss: 0.3250 - val_loss: 0.3426\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.3461 - val_loss: 0.3337\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3419 - val_loss: 0.3306\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3316 - val_loss: 0.3231\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 7s 59ms/step - loss: 0.3315 - val_loss: 0.3299\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3256 - val_loss: 0.3285\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 7s 60ms/step - loss: 0.3250 - val_loss: 0.3294\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3320 - val_loss: 0.3326\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 8s 60ms/step - loss: 0.3217 - val_loss: 0.3289\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 8s 61ms/step - loss: 0.3257 - val_loss: 0.3289\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 16s 114ms/step - loss: 0.1113 - val_loss: 0.0873\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.1143 - val_loss: 0.0877\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.1093 - val_loss: 0.1008\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 0.1044 - val_loss: 0.0950\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 14s 111ms/step - loss: 0.1037 - val_loss: 0.0920\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0986 - val_loss: 0.0901\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0977 - val_loss: 0.0915\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0974 - val_loss: 0.0917\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0955 - val_loss: 0.0903\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 0.0928 - val_loss: 0.0884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model.save('savedmodel')\n",
        "!zip -r savedmodel.zip savedmodel\n",
        "from google.colab import files\n",
        "files.download('savedmodel.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "DrgMH3uzsQ6W",
        "outputId": "41fbfaf6-65a6-4298-f79f-67af87d9a1ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: savedmodel/assets\n",
            "  adding: savedmodel/ (stored 0%)\n",
            "  adding: savedmodel/assets/ (stored 0%)\n",
            "  adding: savedmodel/keras_metadata.pb (deflated 93%)\n",
            "  adding: savedmodel/variables/ (stored 0%)\n",
            "  adding: savedmodel/variables/variables.data-00000-of-00001 (deflated 28%)\n",
            "  adding: savedmodel/variables/variables.index (deflated 70%)\n",
            "  adding: savedmodel/saved_model.pb (deflated 90%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_49197e18-213c-488a-bc95-74c51ff92edd\", \"savedmodel.zip\", 4626511)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_model.summary())\n",
        "_history = train_model_R(selected_model, epochs=40, train_data = train_data_R, valid_data = valid_data_R)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei89IKJ73t-k",
        "outputId": "566ad6c9-c38c-44ee-f3da-ee17dac8e8b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " preprocess (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d_145 (Conv2D)         (None, 128, 128, 8)       608       \n",
            "                                                                 \n",
            " conv2d_146 (Conv2D)         (None, 128, 128, 8)       584       \n",
            "                                                                 \n",
            " conv2d_147 (Conv2D)         (None, 128, 128, 8)       584       \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 128, 128, 8)      32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_71 (MaxPoolin  (None, 64, 64, 8)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_31 (Flatten)        (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 16)                524304    \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 16)                272       \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 526,401\n",
            "Trainable params: 526,385\n",
            "Non-trainable params: 16\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "125/125 [==============================] - 9s 66ms/step - loss: 0.0898 - val_loss: 0.0878\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0896 - val_loss: 0.0869\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0894 - val_loss: 0.0874\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0889 - val_loss: 0.0842\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0889 - val_loss: 0.0879\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0892 - val_loss: 0.1088\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0887 - val_loss: 0.0849\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0892 - val_loss: 0.1115\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0884 - val_loss: 0.0863\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0883 - val_loss: 0.0840\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0887 - val_loss: 0.0970\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0878 - val_loss: 0.0869\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0886 - val_loss: 0.0926\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0880 - val_loss: 0.0834\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0883 - val_loss: 0.0923\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0878 - val_loss: 0.0901\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0881 - val_loss: 0.0834\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0884 - val_loss: 0.0827\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0868 - val_loss: 0.0849\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0874 - val_loss: 0.0848\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0838\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0877 - val_loss: 0.2065\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0877\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0875 - val_loss: 0.0859\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0876 - val_loss: 0.0888\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0873 - val_loss: 0.0871\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0879 - val_loss: 0.0892\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0869 - val_loss: 0.0883\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 8s 65ms/step - loss: 0.0875 - val_loss: 0.0828\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0877 - val_loss: 0.0837\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0870 - val_loss: 0.0870\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0868 - val_loss: 0.0837\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0869 - val_loss: 0.0819\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0872 - val_loss: 0.0835\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 8s 68ms/step - loss: 0.0874 - val_loss: 0.0876\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0875 - val_loss: 0.0836\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0864 - val_loss: 0.0825\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 8s 66ms/step - loss: 0.0874 - val_loss: 0.0821\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 8s 67ms/step - loss: 0.0879 - val_loss: 0.1136\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 9s 70ms/step - loss: 0.0880 - val_loss: 0.0899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_C(model, epochs: int, train_data: tf.data.Dataset, valid_data: tf.data.Dataset):\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    loss = keras.losses.categorical_crossentropy\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "    return model.fit(train_data, epochs=epochs, validation_data=valid_data)"
      ],
      "metadata": {
        "id": "oF5n0dSz7B2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomSearch_C(tr, val, model_amount: int = 30, epochs: int = 10, num_classes: int = 31):\n",
        "  models = []\n",
        "  inputs_C = layers.Input(shape=(None, None, 3), dtype='uint8')\n",
        "  loss_C = np.ndarray(model_amount)\n",
        "  hyperparams_C = list(get_random_hyperparameters(count=model_amount))\n",
        "  for i in range(model_amount):\n",
        "    print(f\"Hiperparâmetros Selecionados:\\n{hyperparams_C[i]}\")\n",
        "    model_C = build_model(inputs_C, **hyperparams_C[i], output_activation = 'softmax', last_dense_neurons_count=num_classes)\n",
        "    history_C = train_model_C(model_C, epochs, train_data = tr, valid_data = val)\n",
        "    models.append(model_C)\n",
        "    loss_C[i] = history_C.history['val_loss'][-1]\n",
        "  idx_C = np.argmin(loss_C)\n",
        "  selected_hyperparams = hyperparams_C[idx_C]\n",
        "  return selected_hyperparams, models[idx_C]"
      ],
      "metadata": {
        "id": "ETsSyiBj62Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 5000\n",
        "validation_split = 0.2\n",
        "\n",
        "train_paths = get_image_paths(all_ages=False, train=True)\n",
        "train_paths_sample = np.random.choice(train_paths, SAMPLE_SIZE)\n",
        "\n",
        "tr_paths_C, valid_paths_C = train_test_split(train_paths_sample, test_size=validation_split)\n",
        "\n",
        "sample_ds_train_C = build_ds_from_paths(tr_paths_C, regression=False)\n",
        "sample_ds_valid_C = build_ds_from_paths(valid_paths_C, regression=False)\n",
        "\n",
        "train_data_C = sample_ds_train_C\n",
        "valid_data_C = sample_ds_valid_C\n",
        "inputs_C = layers.Input(shape=(None, None, 3), dtype='uint8')"
      ],
      "metadata": {
        "id": "fEpXGCd17R8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_hyper_C, selected_model_C = RandomSearch_C(train_data_C, valid_data_C, num_classes=31)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmgkZodA7NOE",
        "outputId": "444762ec-0295-4c92-8b31-dc9e1e544ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 78ms/step - loss: 3.7728 - accuracy: 0.0358 - val_loss: 3.5363 - val_accuracy: 0.0370\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.5817 - accuracy: 0.0327 - val_loss: 3.6086 - val_accuracy: 0.0400\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.5845 - accuracy: 0.0320 - val_loss: 3.6372 - val_accuracy: 0.0310\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.5714 - accuracy: 0.0308 - val_loss: 3.5030 - val_accuracy: 0.0390\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.5712 - accuracy: 0.0302 - val_loss: 3.4937 - val_accuracy: 0.0350\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.5657 - accuracy: 0.0342 - val_loss: 3.5448 - val_accuracy: 0.0210\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.6064 - accuracy: 0.0370 - val_loss: 3.5203 - val_accuracy: 0.0310\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.5789 - accuracy: 0.0335 - val_loss: 3.4933 - val_accuracy: 0.0330\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.5590 - accuracy: 0.0318 - val_loss: 3.4887 - val_accuracy: 0.0390\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.5588 - accuracy: 0.0375 - val_loss: 3.4993 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 32, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 95ms/step - loss: 3.4340 - accuracy: 0.0408 - val_loss: 3.4338 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.4318 - accuracy: 0.0432 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 3.4305 - accuracy: 0.0425 - val_loss: 3.4349 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 13s 101ms/step - loss: 3.4299 - accuracy: 0.0432 - val_loss: 3.4337 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4298 - accuracy: 0.0432 - val_loss: 3.4345 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4283 - accuracy: 0.0443 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4281 - accuracy: 0.0432 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4279 - accuracy: 0.0432 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4279 - accuracy: 0.0432 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 74ms/step - loss: 4.6241 - accuracy: 0.0320 - val_loss: 3.6253 - val_accuracy: 0.0310\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 4.2749 - accuracy: 0.0300 - val_loss: 3.6361 - val_accuracy: 0.0240\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 4.0975 - accuracy: 0.0335 - val_loss: 3.6194 - val_accuracy: 0.0230\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.9813 - accuracy: 0.0358 - val_loss: 3.5761 - val_accuracy: 0.0330\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.8931 - accuracy: 0.0345 - val_loss: 3.5252 - val_accuracy: 0.0310\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.8177 - accuracy: 0.0362 - val_loss: 3.5489 - val_accuracy: 0.0260\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.7778 - accuracy: 0.0340 - val_loss: 3.6100 - val_accuracy: 0.0340\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.7043 - accuracy: 0.0333 - val_loss: 3.5736 - val_accuracy: 0.0270\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.6498 - accuracy: 0.0402 - val_loss: 3.5340 - val_accuracy: 0.0260\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.6534 - accuracy: 0.0340 - val_loss: 3.4891 - val_accuracy: 0.0400\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 80ms/step - loss: 5.3856 - accuracy: 0.0355 - val_loss: 4.9069 - val_accuracy: 0.0230\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4328 - accuracy: 0.0353 - val_loss: 4.9266 - val_accuracy: 0.0230\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4315 - accuracy: 0.0397 - val_loss: 3.6959 - val_accuracy: 0.0340\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4302 - accuracy: 0.0417 - val_loss: 3.4407 - val_accuracy: 0.0420\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4299 - accuracy: 0.0422 - val_loss: 3.4331 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4287 - accuracy: 0.0408 - val_loss: 3.4335 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4287 - accuracy: 0.0443 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4288 - accuracy: 0.0417 - val_loss: 3.4343 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4286 - accuracy: 0.0437 - val_loss: 3.4349 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4283 - accuracy: 0.0400 - val_loss: 3.4352 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 64, 'initial_filter': 32, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 91ms/step - loss: 3.8031 - accuracy: 0.0338 - val_loss: 3.6075 - val_accuracy: 0.0230\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 3.6176 - accuracy: 0.0330 - val_loss: 3.5872 - val_accuracy: 0.0310\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.6096 - accuracy: 0.0347 - val_loss: 3.5717 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5618 - accuracy: 0.0333 - val_loss: 3.5816 - val_accuracy: 0.0310\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5527 - accuracy: 0.0295 - val_loss: 3.5727 - val_accuracy: 0.0340\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5500 - accuracy: 0.0350 - val_loss: 3.5462 - val_accuracy: 0.0370\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5361 - accuracy: 0.0330 - val_loss: 3.5374 - val_accuracy: 0.0410\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5208 - accuracy: 0.0355 - val_loss: 3.5474 - val_accuracy: 0.0410\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.5118 - accuracy: 0.0390 - val_loss: 3.5322 - val_accuracy: 0.0290\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 11s 90ms/step - loss: 3.5020 - accuracy: 0.0353 - val_loss: 3.5219 - val_accuracy: 0.0380\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 81ms/step - loss: 3.6302 - accuracy: 0.0370 - val_loss: 5.2236 - val_accuracy: 0.0290\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4318 - accuracy: 0.0420 - val_loss: 4.4845 - val_accuracy: 0.0280\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4307 - accuracy: 0.0443 - val_loss: 3.7221 - val_accuracy: 0.0310\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4295 - accuracy: 0.0428 - val_loss: 3.4552 - val_accuracy: 0.0390\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4292 - accuracy: 0.0430 - val_loss: 3.4347 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4285 - accuracy: 0.0437 - val_loss: 3.4352 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4284 - accuracy: 0.0430 - val_loss: 3.4355 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4284 - accuracy: 0.0435 - val_loss: 3.4356 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4277 - accuracy: 0.0440 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4280 - accuracy: 0.0425 - val_loss: 3.4361 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 79ms/step - loss: 3.7260 - accuracy: 0.0370 - val_loss: 3.4318 - val_accuracy: 0.0340\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4308 - accuracy: 0.0430 - val_loss: 3.4301 - val_accuracy: 0.0350\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4281 - accuracy: 0.0430 - val_loss: 3.4299 - val_accuracy: 0.0350\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4240 - accuracy: 0.0435 - val_loss: 3.4302 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4248 - accuracy: 0.0428 - val_loss: 3.4451 - val_accuracy: 0.0330\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4206 - accuracy: 0.0417 - val_loss: 3.4329 - val_accuracy: 0.0350\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4156 - accuracy: 0.0507 - val_loss: 3.4317 - val_accuracy: 0.0420\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4130 - accuracy: 0.0477 - val_loss: 3.4339 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4193 - accuracy: 0.0498 - val_loss: 3.4318 - val_accuracy: 0.0410\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4132 - accuracy: 0.0495 - val_loss: 3.4299 - val_accuracy: 0.0370\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 80ms/step - loss: 3.4336 - accuracy: 0.0290 - val_loss: 3.4338 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4311 - accuracy: 0.0405 - val_loss: 3.4339 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4300 - accuracy: 0.0428 - val_loss: 3.4345 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4293 - accuracy: 0.0443 - val_loss: 3.4352 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4293 - accuracy: 0.0415 - val_loss: 3.4356 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4281 - accuracy: 0.0428 - val_loss: 3.4357 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4287 - accuracy: 0.0425 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4286 - accuracy: 0.0425 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4276 - accuracy: 0.0435 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4283 - accuracy: 0.0437 - val_loss: 3.4365 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 77ms/step - loss: 3.4428 - accuracy: 0.0413 - val_loss: 3.4326 - val_accuracy: 0.0350\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.4308 - accuracy: 0.0402 - val_loss: 3.4336 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4302 - accuracy: 0.0435 - val_loss: 3.4336 - val_accuracy: 0.0380\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4283 - accuracy: 0.0435 - val_loss: 3.4330 - val_accuracy: 0.0430\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4235 - accuracy: 0.0483 - val_loss: 3.4381 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4195 - accuracy: 0.0485 - val_loss: 3.4303 - val_accuracy: 0.0380\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4199 - accuracy: 0.0472 - val_loss: 3.4262 - val_accuracy: 0.0430\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4130 - accuracy: 0.0512 - val_loss: 3.4242 - val_accuracy: 0.0410\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4133 - accuracy: 0.0487 - val_loss: 3.4359 - val_accuracy: 0.0400\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4071 - accuracy: 0.0507 - val_loss: 3.4368 - val_accuracy: 0.0400\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 76ms/step - loss: 3.4575 - accuracy: 0.0325 - val_loss: 3.9895 - val_accuracy: 0.0400\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.4351 - accuracy: 0.0420 - val_loss: 4.2998 - val_accuracy: 0.0400\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4311 - accuracy: 0.0420 - val_loss: 3.5444 - val_accuracy: 0.0370\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.4302 - accuracy: 0.0432 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4296 - accuracy: 0.0432 - val_loss: 3.4338 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.4290 - accuracy: 0.0432 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4286 - accuracy: 0.0432 - val_loss: 3.4343 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4281 - accuracy: 0.0432 - val_loss: 3.4348 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.4279 - accuracy: 0.0432 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 83ms/step - loss: 3.4345 - accuracy: 0.0382 - val_loss: 3.4331 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4313 - accuracy: 0.0405 - val_loss: 3.4337 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4302 - accuracy: 0.0437 - val_loss: 3.4342 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4301 - accuracy: 0.0413 - val_loss: 3.4347 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4285 - accuracy: 0.0422 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4296 - accuracy: 0.0417 - val_loss: 3.4357 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4279 - accuracy: 0.0443 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4291 - accuracy: 0.0450 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4290 - accuracy: 0.0420 - val_loss: 3.4356 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4292 - accuracy: 0.0440 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 82ms/step - loss: 3.4337 - accuracy: 0.0370 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4317 - accuracy: 0.0432 - val_loss: 3.4354 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4304 - accuracy: 0.0432 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4296 - accuracy: 0.0432 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4290 - accuracy: 0.0432 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4286 - accuracy: 0.0432 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 3.4284 - accuracy: 0.0432 - val_loss: 3.4360 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4281 - accuracy: 0.0432 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4280 - accuracy: 0.0432 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 79ms/step - loss: 4.5341 - accuracy: 0.0355 - val_loss: 3.6194 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 4.1275 - accuracy: 0.0302 - val_loss: 3.5720 - val_accuracy: 0.0330\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.9956 - accuracy: 0.0330 - val_loss: 3.5786 - val_accuracy: 0.0400\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.8805 - accuracy: 0.0312 - val_loss: 3.4994 - val_accuracy: 0.0490\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.8174 - accuracy: 0.0335 - val_loss: 3.5237 - val_accuracy: 0.0310\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.7463 - accuracy: 0.0320 - val_loss: 3.5076 - val_accuracy: 0.0290\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.7013 - accuracy: 0.0338 - val_loss: 3.4830 - val_accuracy: 0.0350\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.6695 - accuracy: 0.0327 - val_loss: 3.4938 - val_accuracy: 0.0370\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.6067 - accuracy: 0.0325 - val_loss: 3.4785 - val_accuracy: 0.0400\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 3.5663 - accuracy: 0.0400 - val_loss: 3.4708 - val_accuracy: 0.0380\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 8, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 82ms/step - loss: 3.4330 - accuracy: 0.0390 - val_loss: 3.4339 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4303 - accuracy: 0.0415 - val_loss: 3.4357 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4298 - accuracy: 0.0400 - val_loss: 3.4362 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4295 - accuracy: 0.0432 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4293 - accuracy: 0.0432 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4292 - accuracy: 0.0432 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4291 - accuracy: 0.0432 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4290 - accuracy: 0.0432 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4289 - accuracy: 0.0432 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4288 - accuracy: 0.0432 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 1, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 16, 'dropout': 0.5, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 81ms/step - loss: 3.4413 - accuracy: 0.0358 - val_loss: 3.4338 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4330 - accuracy: 0.0402 - val_loss: 3.4336 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4368 - accuracy: 0.0428 - val_loss: 3.4336 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4306 - accuracy: 0.0432 - val_loss: 3.4337 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4296 - accuracy: 0.0432 - val_loss: 3.4339 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4290 - accuracy: 0.0432 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4286 - accuracy: 0.0432 - val_loss: 3.4344 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4280 - accuracy: 0.0432 - val_loss: 3.4348 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4279 - accuracy: 0.0432 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 17s 115ms/step - loss: 3.9096 - accuracy: 0.0360 - val_loss: 3.7885 - val_accuracy: 0.0260\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4322 - accuracy: 0.0408 - val_loss: 3.6287 - val_accuracy: 0.0350\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4307 - accuracy: 0.0420 - val_loss: 3.4558 - val_accuracy: 0.0400\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4298 - accuracy: 0.0422 - val_loss: 3.4340 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 14s 111ms/step - loss: 3.4293 - accuracy: 0.0395 - val_loss: 3.4342 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4291 - accuracy: 0.0450 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4283 - accuracy: 0.0420 - val_loss: 3.4348 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4285 - accuracy: 0.0400 - val_loss: 3.4349 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4281 - accuracy: 0.0443 - val_loss: 3.4352 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 3.4276 - accuracy: 0.0435 - val_loss: 3.4356 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 128, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 22s 161ms/step - loss: 3.5817 - accuracy: 0.0345 - val_loss: 3.5090 - val_accuracy: 0.0350\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 20s 159ms/step - loss: 3.5390 - accuracy: 0.0385 - val_loss: 3.5246 - val_accuracy: 0.0280\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.5574 - accuracy: 0.0308 - val_loss: 3.4822 - val_accuracy: 0.0240\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 20s 157ms/step - loss: 3.5250 - accuracy: 0.0327 - val_loss: 3.4713 - val_accuracy: 0.0400\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 20s 157ms/step - loss: 3.5087 - accuracy: 0.0355 - val_loss: 3.4875 - val_accuracy: 0.0370\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.5038 - accuracy: 0.0370 - val_loss: 3.4717 - val_accuracy: 0.0230\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 20s 157ms/step - loss: 3.4858 - accuracy: 0.0375 - val_loss: 3.4806 - val_accuracy: 0.0410\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4856 - accuracy: 0.0388 - val_loss: 3.4821 - val_accuracy: 0.0450\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 20s 157ms/step - loss: 3.4718 - accuracy: 0.0388 - val_loss: 3.4985 - val_accuracy: 0.0340\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4787 - accuracy: 0.0410 - val_loss: 3.4757 - val_accuracy: 0.0390\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 64, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 74ms/step - loss: 3.4438 - accuracy: 0.0327 - val_loss: 3.4357 - val_accuracy: 0.0340\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4310 - accuracy: 0.0410 - val_loss: 3.4346 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4274 - accuracy: 0.0388 - val_loss: 3.4375 - val_accuracy: 0.0340\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4264 - accuracy: 0.0420 - val_loss: 3.4282 - val_accuracy: 0.0330\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4217 - accuracy: 0.0413 - val_loss: 3.4362 - val_accuracy: 0.0340\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4234 - accuracy: 0.0425 - val_loss: 3.4379 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4207 - accuracy: 0.0480 - val_loss: 3.5074 - val_accuracy: 0.0330\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4184 - accuracy: 0.0492 - val_loss: 3.4611 - val_accuracy: 0.0350\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4158 - accuracy: 0.0503 - val_loss: 3.5161 - val_accuracy: 0.0410\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4110 - accuracy: 0.0468 - val_loss: 3.5142 - val_accuracy: 0.0330\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 78ms/step - loss: 3.4556 - accuracy: 0.0388 - val_loss: 3.4338 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4325 - accuracy: 0.0432 - val_loss: 3.4336 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4311 - accuracy: 0.0432 - val_loss: 3.4336 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4303 - accuracy: 0.0432 - val_loss: 3.4337 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4295 - accuracy: 0.0432 - val_loss: 3.4340 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4304 - accuracy: 0.0430 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4286 - accuracy: 0.0432 - val_loss: 3.4349 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4354 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4280 - accuracy: 0.0432 - val_loss: 3.4357 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4279 - accuracy: 0.0432 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.1, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 84ms/step - loss: 3.5483 - accuracy: 0.0353 - val_loss: 3.6589 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4637 - accuracy: 0.0345 - val_loss: 3.5280 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4474 - accuracy: 0.0355 - val_loss: 4.2771 - val_accuracy: 0.0340\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4382 - accuracy: 0.0370 - val_loss: 3.4443 - val_accuracy: 0.0260\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4358 - accuracy: 0.0335 - val_loss: 3.4410 - val_accuracy: 0.0400\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4342 - accuracy: 0.0417 - val_loss: 3.4358 - val_accuracy: 0.0320\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4349 - accuracy: 0.0373 - val_loss: 3.4406 - val_accuracy: 0.0370\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4348 - accuracy: 0.0437 - val_loss: 3.4392 - val_accuracy: 0.0350\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4301 - accuracy: 0.0415 - val_loss: 3.4341 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4285 - accuracy: 0.0415 - val_loss: 3.4345 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 64, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 82ms/step - loss: 3.4801 - accuracy: 0.0338 - val_loss: 3.4540 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4509 - accuracy: 0.0320 - val_loss: 3.4532 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4498 - accuracy: 0.0342 - val_loss: 3.4525 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 11s 84ms/step - loss: 3.4489 - accuracy: 0.0333 - val_loss: 3.4517 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4480 - accuracy: 0.0338 - val_loss: 3.4506 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4473 - accuracy: 0.0353 - val_loss: 3.4492 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4466 - accuracy: 0.0370 - val_loss: 3.4476 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4461 - accuracy: 0.0362 - val_loss: 3.4462 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4456 - accuracy: 0.0375 - val_loss: 3.4452 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4452 - accuracy: 0.0380 - val_loss: 3.4447 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 128, 'initial_filter': 32, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 16s 114ms/step - loss: 3.7653 - accuracy: 0.0350 - val_loss: 4.6596 - val_accuracy: 0.0320\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4326 - accuracy: 0.0432 - val_loss: 6.7076 - val_accuracy: 0.0320\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4318 - accuracy: 0.0430 - val_loss: 6.6765 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4312 - accuracy: 0.0432 - val_loss: 6.4655 - val_accuracy: 0.0310\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4296 - accuracy: 0.0432 - val_loss: 3.4529 - val_accuracy: 0.0370\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 14s 112ms/step - loss: 3.4291 - accuracy: 0.0432 - val_loss: 3.4340 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4285 - accuracy: 0.0430 - val_loss: 3.4343 - val_accuracy: 0.0350\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4284 - accuracy: 0.0432 - val_loss: 3.4350 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 14s 114ms/step - loss: 3.4407 - accuracy: 0.0440 - val_loss: 171.0272 - val_accuracy: 0.0250\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 14s 113ms/step - loss: 3.4286 - accuracy: 0.0432 - val_loss: 3.4662 - val_accuracy: 0.0330\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 2, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 128, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 85ms/step - loss: 3.4339 - accuracy: 0.0395 - val_loss: 3.4343 - val_accuracy: 0.0370\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 11s 85ms/step - loss: 3.4308 - accuracy: 0.0425 - val_loss: 3.4343 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 3.4306 - accuracy: 0.0435 - val_loss: 3.4349 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4288 - accuracy: 0.0432 - val_loss: 3.4359 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4285 - accuracy: 0.0432 - val_loss: 3.4363 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 3.4284 - accuracy: 0.0432 - val_loss: 3.4364 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4365 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 83ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4365 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4366 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 82ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4366 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': False, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 95ms/step - loss: 3.4380 - accuracy: 0.0358 - val_loss: 3.4341 - val_accuracy: 0.0340\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.4315 - accuracy: 0.0413 - val_loss: 3.4339 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.4300 - accuracy: 0.0443 - val_loss: 3.4345 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.4291 - accuracy: 0.0432 - val_loss: 3.4352 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 11s 92ms/step - loss: 3.4289 - accuracy: 0.0432 - val_loss: 3.4358 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 11s 91ms/step - loss: 3.4285 - accuracy: 0.0432 - val_loss: 3.4362 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 11s 91ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4365 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 11s 91ms/step - loss: 3.4283 - accuracy: 0.0432 - val_loss: 3.4367 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 11s 91ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4368 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 12s 92ms/step - loss: 3.4282 - accuracy: 0.0432 - val_loss: 3.4369 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 3, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 22s 161ms/step - loss: 3.6137 - accuracy: 0.0310 - val_loss: 3.6013 - val_accuracy: 0.0310\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.5373 - accuracy: 0.0400 - val_loss: 3.5293 - val_accuracy: 0.0200\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 20s 160ms/step - loss: 3.5171 - accuracy: 0.0270 - val_loss: 3.5000 - val_accuracy: 0.0350\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 20s 159ms/step - loss: 3.4993 - accuracy: 0.0400 - val_loss: 3.4791 - val_accuracy: 0.0300\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4957 - accuracy: 0.0355 - val_loss: 3.5103 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4847 - accuracy: 0.0380 - val_loss: 3.4727 - val_accuracy: 0.0370\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4724 - accuracy: 0.0420 - val_loss: 3.4563 - val_accuracy: 0.0390\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4721 - accuracy: 0.0408 - val_loss: 3.4785 - val_accuracy: 0.0350\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 20s 158ms/step - loss: 3.4643 - accuracy: 0.0425 - val_loss: 3.4914 - val_accuracy: 0.0370\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 20s 160ms/step - loss: 3.4622 - accuracy: 0.0432 - val_loss: 3.4759 - val_accuracy: 0.0290\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 2, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 16, 'initial_filter': 32, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 12s 80ms/step - loss: 3.4852 - accuracy: 0.0310 - val_loss: 3.4418 - val_accuracy: 0.0360\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4580 - accuracy: 0.0300 - val_loss: 3.4377 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4448 - accuracy: 0.0367 - val_loss: 3.4378 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4501 - accuracy: 0.0358 - val_loss: 3.4392 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4502 - accuracy: 0.0362 - val_loss: 3.4371 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4458 - accuracy: 0.0367 - val_loss: 3.4378 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4430 - accuracy: 0.0335 - val_loss: 3.4391 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4436 - accuracy: 0.0417 - val_loss: 3.4386 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4377 - accuracy: 0.0413 - val_loss: 3.4373 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4443 - accuracy: 0.0365 - val_loss: 3.4376 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 16, 'dropout': 0.0, 'fixed_size_filter': True, 'use_batch_normalization': False, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 11s 76ms/step - loss: 3.4374 - accuracy: 0.0373 - val_loss: 3.4808 - val_accuracy: 0.0230\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 3.4325 - accuracy: 0.0422 - val_loss: 3.4373 - val_accuracy: 0.0350\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4312 - accuracy: 0.0420 - val_loss: 3.4380 - val_accuracy: 0.0360\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4304 - accuracy: 0.0428 - val_loss: 3.4408 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4294 - accuracy: 0.0428 - val_loss: 3.4872 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4295 - accuracy: 0.0432 - val_loss: 3.4384 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4288 - accuracy: 0.0405 - val_loss: 3.4409 - val_accuracy: 0.0370\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 3.4285 - accuracy: 0.0425 - val_loss: 3.4414 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 3.4283 - accuracy: 0.0408 - val_loss: 3.4419 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 3.4281 - accuracy: 0.0402 - val_loss: 3.4417 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 3, 'num_of_hidden_layers': 3, 'neurons_per_hidden_layer': 256, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 13s 91ms/step - loss: 3.6582 - accuracy: 0.0375 - val_loss: 3.6506 - val_accuracy: 0.0340\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.6138 - accuracy: 0.0330 - val_loss: 3.6233 - val_accuracy: 0.0330\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 3.5836 - accuracy: 0.0370 - val_loss: 3.5248 - val_accuracy: 0.0340\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 3.5480 - accuracy: 0.0428 - val_loss: 3.5473 - val_accuracy: 0.0320\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 3.5502 - accuracy: 0.0345 - val_loss: 3.5120 - val_accuracy: 0.0410\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5424 - accuracy: 0.0385 - val_loss: 3.5203 - val_accuracy: 0.0400\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5398 - accuracy: 0.0415 - val_loss: 3.5114 - val_accuracy: 0.0510\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 3.5226 - accuracy: 0.0405 - val_loss: 3.5056 - val_accuracy: 0.0450\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 3.5058 - accuracy: 0.0500 - val_loss: 3.5164 - val_accuracy: 0.0350\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 3.5070 - accuracy: 0.0450 - val_loss: 3.5276 - val_accuracy: 0.0340\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 1, 'num_of_blocks': 1, 'num_of_hidden_layers': 2, 'neurons_per_hidden_layer': 256, 'initial_filter': 8, 'dropout': 0.5, 'fixed_size_filter': False, 'use_batch_normalization': True, 'dense_activation': 'relu'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 10s 74ms/step - loss: 4.0430 - accuracy: 0.0360 - val_loss: 3.4357 - val_accuracy: 0.0280\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4354 - accuracy: 0.0417 - val_loss: 3.4334 - val_accuracy: 0.0360\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4327 - accuracy: 0.0420 - val_loss: 3.4344 - val_accuracy: 0.0370\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4315 - accuracy: 0.0417 - val_loss: 3.4344 - val_accuracy: 0.0360\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 3.4284 - accuracy: 0.0437 - val_loss: 3.4371 - val_accuracy: 0.0370\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 9s 72ms/step - loss: 3.4307 - accuracy: 0.0440 - val_loss: 3.4383 - val_accuracy: 0.0340\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 3.4309 - accuracy: 0.0425 - val_loss: 3.7305 - val_accuracy: 0.0380\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 3.4318 - accuracy: 0.0413 - val_loss: 3.5555 - val_accuracy: 0.0310\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 10s 79ms/step - loss: 3.4296 - accuracy: 0.0415 - val_loss: 3.4356 - val_accuracy: 0.0340\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 10s 81ms/step - loss: 3.4310 - accuracy: 0.0428 - val_loss: 3.4351 - val_accuracy: 0.0360\n",
            "Hiperparâmetros Selecionados:\n",
            "{'num_of_conv_layers_per_block': 2, 'num_of_blocks': 3, 'num_of_hidden_layers': 1, 'neurons_per_hidden_layer': 16, 'initial_filter': 64, 'dropout': 0.1, 'fixed_size_filter': True, 'use_batch_normalization': True, 'dense_activation': 'tanh'}\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 17s 125ms/step - loss: 3.5967 - accuracy: 0.0292 - val_loss: 3.5362 - val_accuracy: 0.0350\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 15s 123ms/step - loss: 3.5075 - accuracy: 0.0308 - val_loss: 3.5901 - val_accuracy: 0.0340\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 3.4927 - accuracy: 0.0390 - val_loss: 3.5225 - val_accuracy: 0.0370\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 15s 123ms/step - loss: 3.4760 - accuracy: 0.0350 - val_loss: 3.4968 - val_accuracy: 0.0270\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 15s 123ms/step - loss: 3.4604 - accuracy: 0.0330 - val_loss: 3.4444 - val_accuracy: 0.0360\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 16s 126ms/step - loss: 3.4627 - accuracy: 0.0362 - val_loss: 3.4404 - val_accuracy: 0.0360\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 3.4648 - accuracy: 0.0355 - val_loss: 3.4374 - val_accuracy: 0.0360\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 3.4626 - accuracy: 0.0402 - val_loss: 3.4368 - val_accuracy: 0.0360\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 3.4582 - accuracy: 0.0415 - val_loss: 3.4371 - val_accuracy: 0.0360\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 15s 122ms/step - loss: 3.4540 - accuracy: 0.0390 - val_loss: 3.4376 - val_accuracy: 0.0370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_model_C.save('savedmodelc')\n",
        "!zip -r savedmodelc.zip savedmodelc\n",
        "from google.colab import files\n",
        "files.download('savedmodelc.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "lIGVdp8o-J4P",
        "outputId": "cd6c7256-13a6-4989-f508-27c81ebb7151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: savedmodelc/assets\n",
            "updating: savedmodelc/ (stored 0%)\n",
            "updating: savedmodelc/assets/ (stored 0%)\n",
            "updating: savedmodelc/keras_metadata.pb (deflated 93%)\n",
            "updating: savedmodelc/variables/ (stored 0%)\n",
            "updating: savedmodelc/variables/variables.data-00000-of-00001 (deflated 45%)\n",
            "updating: savedmodelc/variables/variables.index (deflated 67%)\n",
            "updating: savedmodelc/saved_model.pb (deflated 90%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fa1bbdfd-df12-4151-bdec-72b659a11f05\", \"savedmodelc.zip\", 221188472)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_model_C.summary())\n",
        "_history = train_model_R(selected_model_C, epochs=40, train_data = train_data_C, valid_data = valid_data_C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Gq3D7ws-Pf1",
        "outputId": "309835b9-3e49-4557-b085-b542c481982e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, None, None, 3)]   0         \n",
            "                                                                 \n",
            " preprocess (Sequential)     (None, 128, 128, 3)       0         \n",
            "                                                                 \n",
            " conv2d_274 (Conv2D)         (None, 128, 128, 8)       608       \n",
            "                                                                 \n",
            " conv2d_275 (Conv2D)         (None, 128, 128, 32)      2336      \n",
            "                                                                 \n",
            " max_pooling2d_129 (MaxPooli  (None, 64, 64, 32)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " flatten_57 (Flatten)        (None, 131072)            0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 256)               33554688  \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 31)                7967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33,631,391\n",
            "Trainable params: 33,631,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/40\n",
            "125/125 [==============================] - 10s 75ms/step - loss: 0.0312 - val_loss: 0.0312\n",
            "Epoch 2/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0312 - val_loss: 0.0312\n",
            "Epoch 3/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0312 - val_loss: 0.0312\n",
            "Epoch 4/40\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0312 - val_loss: 0.0312\n",
            "Epoch 5/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 6/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0312 - val_loss: 0.0312\n",
            "Epoch 7/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 8/40\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 9/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 10/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 11/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 12/40\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 13/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 14/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 15/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 16/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 17/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 18/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 19/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0311 - val_loss: 0.0312\n",
            "Epoch 20/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 21/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 22/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 23/40\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 24/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0311 - val_loss: 0.0313\n",
            "Epoch 25/40\n",
            "125/125 [==============================] - 10s 80ms/step - loss: 0.0310 - val_loss: 0.0314\n",
            "Epoch 26/40\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 27/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 28/40\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 29/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 30/40\n",
            "125/125 [==============================] - 9s 75ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 31/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 32/40\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0309 - val_loss: 0.0313\n",
            "Epoch 33/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0310 - val_loss: 0.0313\n",
            "Epoch 34/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0309 - val_loss: 0.0314\n",
            "Epoch 35/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0309 - val_loss: 0.0312\n",
            "Epoch 36/40\n",
            "125/125 [==============================] - 10s 76ms/step - loss: 0.0309 - val_loss: 0.0313\n",
            "Epoch 37/40\n",
            "125/125 [==============================] - 9s 73ms/step - loss: 0.0309 - val_loss: 0.0313\n",
            "Epoch 38/40\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0309 - val_loss: 0.0313\n",
            "Epoch 39/40\n",
            "125/125 [==============================] - 9s 76ms/step - loss: 0.0308 - val_loss: 0.0313\n",
            "Epoch 40/40\n",
            "125/125 [==============================] - 9s 74ms/step - loss: 0.0309 - val_loss: 0.0313\n"
          ]
        }
      ]
    }
  ]
}